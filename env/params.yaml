setup:
  observation_dim : 9
  action_dim : 13
  DDQN : True
  actions : [-1.0, -0.5, -0.3, -0.2, -0.1, 0, 0.1, 0.2, 0.3, 0.5, 1.0]
  state_headers : ["date", 
                  "passage_time", 
                  "apoapsis_radius", 
                  "periapsis_altitude", 
                  "inclination", 
                  "AOP", 
                  "RAAN", 
                  "max_heat_rate", 
                  "max_air_density", 
                  "target_apoapsis_radius"]

policies:
  decay_rate : 3000
  discount_rate : 0.95

neural_network:
  hidden_dim : 1024
  hidden_layers : 2
  activation : ReLU
  output_activation : Identity
  target_network_update_frequency : 10000
  lambda_target_network : 1.0
  learning_rate : 0.0005

training:
  train_start_steps : 500 # Training starts only after 500 steps have been taken
  train_stop_steps : 300000 # Training stops once 300,000 steps have been taken
  buffer_size : 20000 # Buffer only stores that latest 20,000 steps
  train_frequency : 3 # Training occurs once every three steps
  eval_episodes : 40 # Evaluate over 40 episodes
  eval_frequency : 5000 # Evaluate policy every 5,000 environment steps
  batch_size : 128

environment:
  apoapsis_radius_initial : 10038000
  apoapsis_radius_target : 4096000
  periapsis_altitude_initial : 92000
  apoapsis_radius_dispersion : 2500
  periapsis_altitude_dispersion : 2500
  inclination_low : 88.6
  inclination_high : 98.6
  raan_low : 110
  raan_high : 120
  aop_low : 70
  aop_high : 90
  nu_dispersion : 0.025

termination:
  apoapsis_radius_tolerance : 10000
  low_heat_rate : 0.05
  high_heat_rate : 0.25
  high_altitude : 135000
  low_altitude : 85000

